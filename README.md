ğŸš€ Overview

  This project showcases a real-time Sign Language Detector that uses AI to recognize common sign language gestures via a webcam. Built with TensorFlow Object Detection API and OpenCV, this system demonstrates the power of computer vision in accessibility and communication.


ğŸ”¥ Key Highlights:

ğŸ“¸ Image Collection â€“ Captured real-world sign language poses.

ğŸ·ï¸ Data Labeling â€“ Processed dataset with accurate annotations.

ğŸ”„ Transfer Learning â€“ Leveraged pre-trained models for efficiency.

ğŸ¯ Real-Time Detection â€“ Detects gestures instantly via a webcam.
  
ğŸš€ AI-Powered Model â€“ Based on SSD MobileNet V2 for fast predictions.


ğŸ“Š Dataset & Model Training

  ğŸ“· Image Collection & Annotation
  
The dataset consists of multiple labeled images representing five key sign language gestures:

    âœ‹ Hello
    ğŸ‘ Yes
    ğŸ‘ No
    ğŸ™ Thank You
    ğŸ¤Ÿ I Love You
Annotation Process:

Using LabelImg, bounding boxes were drawn to accurately label gestures. This ensures the model understands distinct hand shapes.


ğŸ—ï¸ Model Training & Optimization

Training was conducted using transfer learning with TensorFlowâ€™s SSD MobileNet V2 architecture, leveraging pre-trained weights for improved accuracy.

ğŸ”¹ Steps in Training:

Pre-processing â€“ Convert labeled images into TFRecords.

Fine-Tuning â€“ Train the model on sign language gestures.

Performance Evaluation â€“ Validate results with unseen test data.


ğŸ™Œ Acknowledgments

  ğŸ† TensorFlow Object Detection API â€“ https://github.com/tensorflow/models
  
  ğŸ“¸ OpenCV â€“ https://opencv.org/
  
  ğŸ·ï¸ LabelImg â€“ https://github.com/tzutalin/labelImg


